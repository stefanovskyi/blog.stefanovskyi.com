<!DOCTYPE html>
<html lang="en-us">
<head>
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <script type="text/javascript" src="https://latest.cactus.chat/cactus.js"></script>
  <link rel="stylesheet" href="https://latest.cactus.chat/style.css" type="text/css">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> Mitigating Undesirable Outputs from Large Language Models | Oleksandr Stefanovskyi Blog</title>
  <link rel = 'canonical' href = 'https://blog.stefanovskyi.com/posts/mitigate-llm-risks/'>
  <meta name="description" content="[Head of R&amp;D](https://stefanovskyi.com/) with expertise in AWS, software architecture, and Python development. Specializes in creating applications powered by Large Language Models alongside a team of engineers. Committed to advancing in Software Architecture and English proficiency. Based in Lviv, Ukraine, and focused on innovative technology solutions.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:title" content="Mitigating Undesirable Outputs from Large Language Models" />
<meta property="og:description" content="Understanding and Overcoming the Risks of Deploying LLMs in Business Applications The Risks Hallucinations
LLMs can generate plausible but false content. For instance, summarizing a meeting might lead to fabricated events. Data Poisoning
LLMs trained on biased or incorrect data can produce harmful outputs, spreading those biases or falsehoods. Toxic Language
LLMs can inadvertently generate hate speech, abuse, or profanity, reflecting the worst elements of their training data. Unstable Performance" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.stefanovskyi.com/posts/mitigate-llm-risks/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-30T02:04:26+02:00" />
<meta property="article:modified_time" content="2023-08-30T02:04:26+02:00" />


  <meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Mitigating Undesirable Outputs from Large Language Models"/>
<meta name="twitter:description" content="Understanding and Overcoming the Risks of Deploying LLMs in Business Applications The Risks Hallucinations
LLMs can generate plausible but false content. For instance, summarizing a meeting might lead to fabricated events. Data Poisoning
LLMs trained on biased or incorrect data can produce harmful outputs, spreading those biases or falsehoods. Toxic Language
LLMs can inadvertently generate hate speech, abuse, or profanity, reflecting the worst elements of their training data. Unstable Performance"/>

  
  
    
  
  
  <link rel="stylesheet" href="https://blog.stefanovskyi.com/css/styles.c05d68261bf086a9d7713c4f8a6215a3601608e267a816a7ee58f139b3d1aae51222aae2081c8e0c6bd35e1334773b7a16283022f31f92afd93bb37e5e822e66.css" integrity="sha512-wF1oJhvwhqnXcTxPimIVo2AWCOJnqBan7ljxObPRquUSIqriCByODGvTXhM0dzt6FigwIvMfkq/ZO7N&#43;XoIuZg=="> 

  
  
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="https://blog.stefanovskyi.com/images/favicon.ico" />

  
  
</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

  <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;" aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
        <li><a href="/posts">All posts</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li>
          <a class="icon" href=" https://blog.stefanovskyi.com/posts/designing-data-intensive-applications/" aria-label="Previous">
            <i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i>
          </a>
        </li>
        
        
        <li>
          <a class="icon" href="https://blog.stefanovskyi.com/posts/evolve-or-be-extinct/" aria-label="Next">
            <i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i>
          </a>
        </li>
        
        <li>
          <a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" aria-label="Top of Page">
            <i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i>
          </a>
        </li>
        <li>
          <a class="icon" href="#" aria-label="Share">
            <i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i>
          </a>
        </li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f" aria-label="Facebook">
      <i class="fab fa-facebook " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&text=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="Twitter">
      <i class="fab fa-twitter " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&title=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="Linkedin">
      <i class="fab fa-linkedin " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&is_video=false&description=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="Pinterest">
      <i class="fab fa-pinterest " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models&body=Check out this article: https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f" aria-label="Email">
      <i class="fas fa-envelope " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&title=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="Pocket">
      <i class="fab fa-get-pocket " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&title=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="reddit">
      <i class="fab fa-reddit " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&name=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models&description=Understanding%20and%20Overcoming%20the%20Risks%20of%20Deploying%20LLMs%20in%20Business%20Applications%20The%20Risks%20Hallucinations%0aLLMs%20can%20generate%20plausible%20but%20false%20content.%20For%20instance%2c%20summarizing%20a%20meeting%20might%20lead%20to%20fabricated%20events.%20Data%20Poisoning%0aLLMs%20trained%20on%20biased%20or%20incorrect%20data%20can%20produce%20harmful%20outputs%2c%20spreading%20those%20biases%20or%20falsehoods.%20Toxic%20Language%0aLLMs%20can%20inadvertently%20generate%20hate%20speech%2c%20abuse%2c%20or%20profanity%2c%20reflecting%20the%20worst%20elements%20of%20their%20training%20data.%20Unstable%20Performance" aria-label="Tumblr">
      <i class="fab fa-tumblr " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&t=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="Hacker News">
      <i class="fab fa-hacker-news " aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>
    
    <div id="toc">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#understanding-and-overcoming-the-risks-of-deploying-llms-in-business-applications">Understanding and Overcoming the Risks of Deploying LLMs in Business Applications</a></li>
  </ul>
</nav>
    </div>
    
  </span>
</div>


  <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
      <h1 class="posttitle" itemprop="name headline">
        Mitigating Undesirable Outputs from Large Language Models
      </h1>
      <div class="meta">
        
        <div class="postdate">
          
          <time datetime="2023-08-30 02:04:26 &#43;0200 &#43;0200" itemprop="datePublished">2023-08-30</time>
          
        </div>
        
        
        
        
      </div>
    </header>

  
    
    <div class="content" itemprop="articleBody">
      <h2 id="understanding-and-overcoming-the-risks-of-deploying-llms-in-business-applications">Understanding and Overcoming the Risks of Deploying LLMs in Business Applications</h2>
<h1 id="the-risks">The Risks</h1>
<ul>
<li><strong>Hallucinations</strong><br>
LLMs can generate plausible but false content. For instance, summarizing a meeting might lead to fabricated events.</li>
<li><strong>Data Poisoning</strong><br>
LLMs trained on biased or incorrect data can produce harmful outputs, spreading those biases or falsehoods.</li>
<li><strong>Toxic Language</strong><br>
LLMs can inadvertently generate hate speech, abuse, or profanity, reflecting the worst elements of their training data.</li>
<li><strong>Unstable Performance</strong><br>
These models can vary wildly in their output quality, providing accurate summaries one moment and nonsensical information the next.</li>
<li><strong>Lack of Verification</strong><br>
LLMs can’t self-verify the factual correctness of their outputs, leading to potentially false or misleading information.</li>
</ul>
<h1 id="overcoming-the-risks">Overcoming the Risks</h1>
<ul>
<li><strong>Prompt Engineering</strong><br>
Carefully design your prompts to guide the model towards generating the desired output while avoiding pitfalls like hallucination.</li>
<li><strong>Data Curation</strong><br>
Use a dataset that has been meticulously curated to minimize biases and inaccuracies, reducing the risks of data poisoning.</li>
<li><strong>Output Filtering</strong><br>
Employ automated tools to filter out hate speech, false information, and other harmful content from the model’s outputs.</li>
<li><strong>Human Oversight</strong><br>
Implement a human-in-the-loop system where experts review high-stakes outputs before being acted upon.</li>
<li><strong>Continuous Training</strong><br>
Keep the model updated, focusing on safety and truthfulness to mitigate its limitations.</li>
<li><strong>External Verification</strong><br>
Connect the model to verified external databases for fact-checking, providing a layer of accuracy to the outputs.</li>
</ul>
<h1 id="conclusion">Conclusion</h1>
<p>The use of Large Language Models presents a significant advantage in various applications but comes with challenges and risks. Combining prompt engineering, data curation, output filtering, and human oversight can mitigate these risks effectively.</p>
<p>Understanding these drawbacks and their solutions is essential for anyone considering implementing LLMs in a business environment, ensuring responsible and safe AI usage.</p>

    </div>
  </article>

  
  






  <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/posts">All posts</a></li>
        
      </ul>
    </div>

    
    <div id="toc-footer" style="display: none">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#understanding-and-overcoming-the-risks-of-deploying-llms-in-business-applications">Understanding and Overcoming the Risks of Deploying LLMs in Business Applications</a></li>
  </ul>
</nav>
    </div>
    

    <div id="share-footer" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f" aria-label="Facebook">
      <i class="fab fa-facebook fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&text=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="Twitter">
      <i class="fab fa-twitter fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&title=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="Linkedin">
      <i class="fab fa-linkedin fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&is_video=false&description=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="Pinterest">
      <i class="fab fa-pinterest fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models&body=Check out this article: https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f" aria-label="Email">
      <i class="fas fa-envelope fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&title=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="Pocket">
      <i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&title=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="reddit">
      <i class="fab fa-reddit fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&name=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models&description=Understanding%20and%20Overcoming%20the%20Risks%20of%20Deploying%20LLMs%20in%20Business%20Applications%20The%20Risks%20Hallucinations%0aLLMs%20can%20generate%20plausible%20but%20false%20content.%20For%20instance%2c%20summarizing%20a%20meeting%20might%20lead%20to%20fabricated%20events.%20Data%20Poisoning%0aLLMs%20trained%20on%20biased%20or%20incorrect%20data%20can%20produce%20harmful%20outputs%2c%20spreading%20those%20biases%20or%20falsehoods.%20Toxic%20Language%0aLLMs%20can%20inadvertently%20generate%20hate%20speech%2c%20abuse%2c%20or%20profanity%2c%20reflecting%20the%20worst%20elements%20of%20their%20training%20data.%20Unstable%20Performance" aria-label="Tumblr">
      <i class="fab fa-tumblr fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fblog.stefanovskyi.com%2fposts%2fmitigate-llm-risks%2f&t=Mitigating%20Undesirable%20Outputs%20from%20Large%20Language%20Models" aria-label="Hacker News">
      <i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>

    <div id="actions-footer">
      
        <a id="menu-toggle" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;" aria-label="Menu">
          <i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
        <a id="toc-toggle" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;" aria-label="TOC">
          <i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share-toggle" class="icon" href="#" onclick="$('#share-footer').toggle();return false;" aria-label="Share">
          <i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" aria-label="Top of Page">
          <i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>


  <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2024  Oleksandr Stefanovskyi Blog 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/posts">All posts</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
</body>

<link rel="stylesheet" href=/lib/font-awesome/css/all.min.css>
<script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>

<script src=/js/code-copy.js></script>




</html>
